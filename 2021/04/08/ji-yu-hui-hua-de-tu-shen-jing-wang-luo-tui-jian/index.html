<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>基于会话的图神经网络推荐 | TechAoba的博客</title><meta name="keywords" content="NLP,论文,推荐"><meta name="author" content="TechAoba"><meta name="copyright" content="TechAoba"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Session-Based Recommendation with Graph Neural Networks  摘要  &amp;#8195;&amp;#8195;基于会话的推荐旨在匿名用户会话中预测用户行为。以前的方法将会话建模为一个序列并通过预测用户表征和物品表征来做出推荐。虽然这种方法取得了不错的结果，但是它并没有在会话中获取精确的用户向量，同时也忽略了复杂的item transition。为了解决这两个">
<meta property="og:type" content="article">
<meta property="og:title" content="基于会话的图神经网络推荐">
<meta property="og:url" content="http://techaoba.github.io/2021/04/08/ji-yu-hui-hua-de-tu-shen-jing-wang-luo-tui-jian/index.html">
<meta property="og:site_name" content="TechAoba的博客">
<meta property="og:description" content="Session-Based Recommendation with Graph Neural Networks  摘要  &amp;#8195;&amp;#8195;基于会话的推荐旨在匿名用户会话中预测用户行为。以前的方法将会话建模为一个序列并通过预测用户表征和物品表征来做出推荐。虽然这种方法取得了不错的结果，但是它并没有在会话中获取精确的用户向量，同时也忽略了复杂的item transition。为了解决这两个">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2021-04-08T13:50:14.000Z">
<meta property="article:modified_time" content="2021-05-28T11:49:26.174Z">
<meta property="article:author" content="TechAoba">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="论文">
<meta property="article:tag" content="推荐">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://techaoba.github.io/2021/04/08/ji-yu-hui-hua-de-tu-shen-jing-wang-luo-tui-jian/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '基于会话的图神经网络推荐',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-05-28 19:49:26'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="TechAoba的博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">TechAoba的博客</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">基于会话的图神经网络推荐</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-04-08T13:50:14.000Z" title="发表于 2021-04-08 21:50:14">2021-04-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-05-28T11:49:26.174Z" title="更新于 2021-05-28 19:49:26">2021-05-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="基于会话的图神经网络推荐"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Session-Based-Recommendation-with-Graph-Neural-Networks"><a href="#Session-Based-Recommendation-with-Graph-Neural-Networks" class="headerlink" title="Session-Based Recommendation with Graph Neural Networks"></a>Session-Based Recommendation with Graph Neural Networks</h1><br>

<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><hr>

<p>&#8195;&#8195;基于会话的推荐旨在匿名用户会话中预测用户行为。以前的方法将会话建模为一个序列并通过预测用户表征和物品表征来做出推荐。虽然这种方法取得了不错的结果，但是它并没有在会话中获取精确的用户向量，同时也忽略了复杂的item transition。为了解决这两个问题，提出了<strong>SR-GNN</strong>模型。在此模型中，会话序列被建模为图形结构的数据，结合GNN捕捉复杂的item transition，达到常规序列方法难以实现的效果。然后使用attention网络把每一段对话表征为全局偏好和目前兴趣的组成部分。接下来在两个真实数据集上进行实验，结果表明SR-GNN的表现优于最先进的基于会话推荐的方法。</p>
<br>

<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><hr>

<p>&#8195;&#8195;随着网络信息的迅速发展，推荐系统极大地帮助用户减轻信息过载的问题并在许多互联网应用中挑选出有意思的信息。比如搜索，电商和视频流网站。大多数现存推荐系统假定用户的配置文件和动作信息在不断地记录着。但是也有很多服务网站用户的信息是未知的，仅仅有该用户在该会话区间的信息可用。因此，在一个有限的单次会话中捕获用户的行为并生成相应的推荐就变得尤为重要。相反的，传统依赖于充足user-item交互的推荐方法对于该场景下的推荐得出的结果就差强人意了。</p>
<p>&#8195;&#8195;由于该推荐具有很好的实用价值，现在对于这一问题的研究也越来越多，相继产生了一些解决基于会话的推荐方案。比如有基于马尔可夫链的，通过用户本次行为预测下一次行为，它带有强独立性假设，因此预测准确度不高。近几年，主要的研究采用Recurrent Neural Networks$($RNN$)$方法得到了不错的结果。首先提出了RNN网络方法，之后有工作在该模型上进行数据增广和考虑用户行为的时间变化。近期，NARM模型设计了全局和局部RNN推荐系统来同时捕获用户的sequential hehavior和main purpose。STAMP模型和NARM类似，STAMP通过使用多层感知机和注意力网络捕获用户的general interest和current interest。</p>
<p>&#8195;&#8195;虽然这些先进的方法得到了不错的结果，但依然存在着不足。第一，缺少充足的用户行为信息，导致它们很难估计用户表征。通常来说，这些RNN方法的hidden vector看作是用户表征，然后推荐系统可以通过这些表征生成相应的推荐，就比如NARM模型的全局推荐器。然而在基于会话推荐系统中，会话大多数是匿名的，并且用户在会话中的行为也是有限的，因此很难在会话中精确地预测用户的表征。第二，之前的工作证实item transitions模式的重要性，可以把它用作会话推荐局部的因子，但这些方法总是在连续物品间建立单一transitions而忽视了其他物品的transitions。因此，远距离物品间的复杂转换被这些方法所忽视。</p>
<p>&#8195;&#8195;为了解决以上提到的问题，提出了一个全新的模型$\underline{S}ession-based\ \underline{R}ecommendation\ with\ \underline{G}raph\ \underline{N}eural\ \underline{N}etworks$，简称SR-GNN，该模型用于探究物品间丰富的transition并产生精确的物品隐式向量。GNN被设计用来生成图的表征。近期，它被广泛用于自然语言处理和计算机视觉应用的图结构依赖模型，比如脚本事件预测、情景识别和图片分类。对于会话推荐，我们首先对于历史会话序列进行有向图的构建，对于会话图，GNN可以捕捉到物品间的transition并精确地预测相应的嵌入向量，这是传统序列模型难以做到的。基于精确的物品嵌入向量，SR-GNN构建更多的会话表征，最终可以推断用户的下一次点击。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/cUIKnU"><img src="https://z3.ax1x.com/2021/04/10/cUIKnU.jpg" alt="Figure 1"></a></p>
<p>&#8195;&#8195;Figure 1画出了SR-GNN方法的工作流程。首先，所有的序列被建模为有向会话图，其中每一个会话可以看作它的子图。然后，每个子图连续地输入到GNN中得到子图中节点的隐含向量。接下来，把所有会话组成全局偏好，一次会话作为用户的当前兴趣，这些全局和局部会话嵌入向量都是由节点的隐含向量组成的。该论文的贡献有以下几点：</p>
<ul>
<li>把分离的会话序列建模为图结构数据并使用图结构捕获物品的复杂转换。</li>
<li>为了生成基于会话的推荐系统，不依赖于用户表征，但是使用会话嵌入，该会话嵌入可以仅通过单次会话中的物品的隐含向量所得到。</li>
<li>在两个真实数据集上进行的实验表明我们提出的SR-GNN的表现明显超过最先进的方法。</li>
</ul>
<br>

<h2 id="2-相关工作"><a href="#2-相关工作" class="headerlink" title="2 相关工作"></a>2 相关工作</h2><hr>

<p>&#8195;&#8195;<strong>传统推荐方法</strong>。矩阵分解方法是推荐系统的一个常用方法，基本的目标是把user-item rating矩阵分解为两个子矩阵，分别表示用户因子矩阵和物品因子矩阵。矩阵分解方法不适用于会话推荐，因为会话推荐中的用户偏好仅仅通过用户的点击获取。item-based的协同推荐方法也是一种惯用方法。这些方法很难考虑物品间的顺序以及仅仅通过最后一次点击生成预测结果。</p>
<p>&#8195;&#8195;于是基于马尔可夫链的序列方法就产生了，它通过用户上一次的点击来预测本次行为。Shani等人把推荐生成视作一种序列优化问题采用马尔科夫决策过程$(MDPs)$。然而马尔可夫链方法的缺点是独立地结合了之前的组件。这样的独立性假设太强了，因此限制了预测的准确性。</p>
<p>&#8195;&#8195;<strong>基于深度学习的方法</strong>。近几年，以语言模型为代表的预测模型采用了神经网络。在众多语言模型中，RNN在建模句子方面是最成功的模型，并在各种自然语言处理任务中蓬勃发展，比如机器翻译，对话机器人，图像理解。RNN也已成功应用于众多应用中，如序列点击预测，位置预测next basket推荐。</p>
<p>&#8195;&#8195;对于会话推荐，有人提出RNN方法，紧接着拓展到并行RNN的体系结构，该结构可以基于点击以及点击物品的特征来建模会话。在此之后，有人通过适当的数据增强技术并考虑同户行为的时间变化来提升RNN模型的性能。</p>
<p>&#8195;&#8195;Jannach和Ludewig将RNN和最近邻居的方法结合在一起，以混合顺序模式和共现信号。 Tuan和Phuong将会话点击与诸如项目描述和物品类别等内容特征相结合，以使用3维卷积神经网络生成推荐。此外，基于列表的深度神经网络对每个会话中受限的用户行为进行建模，并使用基于列表的排名模型为每个会话生成推荐。此外，具有编码器-解码器架构的神经注意推荐机在RNN上采用了注意机制，以捕获用户的顺序行为和主要目的特征。然后，提出了使用简单的MLP网络和注意力网络的短期注意力优先级模型，STAMP，以有效地捕获用户的全局偏好和当前偏好。</p>
<p>&#8195;&#8195;<strong>图上的神经网络</strong>。如今，神经网络已被应用于图结构数据的表征，例如社交网络和知识库。为了拓展word2vec，一种无监督算法DeepWalk被设计为学习基于随机游走的图节点表征。继DeepWalk之后，无监督网络嵌入算法LINE和node2vec是最具代表性的方法。可扩展的方法通过频谱图卷积的局部近似来选择卷积架构，这是一种有效的变体，也可以直接在图上运行。但是，这些方法只能在无向图上实现。GNN则是在有向图上执行的模型。作为对GNN的修改，门控GNN使用门控循环单元，并通过时间进行反向传播$(BPTT)$来计算梯度。最近，GNN被广泛应用于不同的任务，例如脚本事件预测，情境识别和图像分类 。</p>
<br>

<h2 id="3-SR-GNN模型"><a href="#3-SR-GNN模型" class="headerlink" title="3 SR-GNN模型"></a>3 SR-GNN模型</h2><hr>

<h3 id="3-1-定义"><a href="#3-1-定义" class="headerlink" title="3.1 定义"></a>3.1 定义</h3><p>&#8195;&#8195;基于会话的推荐系统旨在预测用户下一次将单击哪个物品，仅根据用户当前的连续会话数据，而不访问长期的偏好。接下来给出该问题的定义：</p>
<p>&#8195;&#8195;在会话推荐中，定义$V={v_1,v_2,…,v_m}$代表在所有会话中所包含的物品集合，在一次匿名会话s中，用户点击的物品按照时间戳进行排序得到一个序列$s=[v_{s,1},v_{s,2},…,v_{s,n}]$。会话推荐的目标是预测下一次用户点击动作，就是会话s的$v_{s,n+1}$。对于会话s，我们对于所有可能的物品输出概率$\hat{y}$，即对应各物品的推荐得分。在$\hat{y}$中具有top-K的物品将成为推荐的候选。</p>
<h3 id="3-2-构建会话图"><a href="#3-2-构建会话图" class="headerlink" title="3.2 构建会话图"></a>3.2 构建会话图</h3><p>&#8195;&#8195;每一个会话序列s都可以被建模为一个有向图$G_s=(V_s,\varepsilon_s)$。在这个会话图中，每一个节点都表示一个物品$v_{s,i}\in V$。边$(v_{s,i-1},v_{s,i})$表示在会话s中用户点击$v_{s,i-1}$后点击了物品$v_{s,i}$。<strong>由于若干物品可能在序列中重复出现，我们为每一条边赋值一个归一化加权值，该加权值计算为改变出现次数/该边起点的出度</strong>。我们把每个物品嵌入到统一的向量空间当中，节点向量$v\in R^d$表示通过GNN学习到的物品v的潜在向量，d为空间维数。基于节点向量，每一个会话s每一个会话s都可以被表示为由节点向量组成的嵌入向量<strong>s</strong>。</p>
<h3 id="3-3-在会话图中学习物品嵌入"><a href="#3-3-在会话图中学习物品嵌入" class="headerlink" title="3.3 在会话图中学习物品嵌入"></a>3.3 在会话图中学习物品嵌入</h3><p>&#8195;&#8195;vanilla graph neural network是2009年提出的拓展处理图结构数据的神经网络方法。2015年Li等人进一步引入了门控循环单元，并提出了门控GNN。GNN非常适合于会话推荐系统，因为他可以在处理丰富节点连接的情况下自动提取会话图的特征。首先给出在会话图中节点向量的学习过程，形式上，对于图$G_s$上的节点$v_{s,i}$，更新函数定义如下：</p>
<p>$$<br>a^t_{s,i}=A_{s,i:}[v_1^{t-1},…,v_n^{t-1}]^TH+b,\tag{1}<br>$$</p>
<p>$$<br>z^t_{s,i}=\sigma(W_za^t_{s,i}+U_zv_i^{t-1}),\tag{2}<br>$$</p>
<p>$$<br>r^t_{s,i}=\sigma(W_ra^t_{s,i}+U_rv_i^{t-1}),\tag{3}<br>$$</p>
<p>$$<br>\tilde{v}^t_i=tanh(W_oa^t_{s,i}+U_o(r^t_{s,i}\odot v_i^{t-1})),\tag{4}<br>$$</p>
<p>$$<br>v_i^t=(1-z^t_{s,i})\odot v_i^{t-1} + z^t_{s,i}\odot \tilde{v}^t_i,\tag{5}<br>$$</p>
<p>其中$H\in R^{d\times 2d}$控制权重，$z_{s,i}和r_{s,i}$分别是reset gates和update gates，$[v_1^{t-1},…,v_n^{t-1}]$为会话s中的节点列表，$v_i\in R^d$表示会话s中第i个节点的隐含表示。连接矩阵$A_s\in R^{n\times 2n}$表示节点之间连接的情况，$A_{s,i:}\in R^{1\times 2n}$表示节点$v_{s,i}$与其他节点连接的情况。在这里$A_s$定义为矩阵$A_s^{(out)}和A_s^{(in)}$的拼接，这两个邻接矩阵分别代表会话图中节点出边和入边的加权值。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/cyKKij"><img src="https://z3.ax1x.com/2021/04/13/cyKKij.jpg" alt="Figure 2"></a></p>
<p>&#8195;&#8195;举一个例子，Figure 2中有一个会话$[v_1,v_2,v_3,v_2,v_4]$，左和右矩阵分别出矩阵和入矩阵。</p>
<p>&#8195;&#8195;公式1计算的是一个节点和其他所有节点信息传播的一个总体信息。然后，这里的$z^t_{s,i}和r^t_{s,i}$分别是update gate和reset gate，分别决定哪些信息会被保留和丢弃。在公式4中，我们用前面的状态、目前的状态以及reset gate计算出候选状态。最终的状态是结合之前的隐藏状态、候选状态，在update gate的控制下计算得到。在更新会话图中的所有节点知道收敛，我们可以得到最终的节点向量。</p>
<h3 id="3-4-生成会话嵌入"><a href="#3-4-生成会话嵌入" class="headerlink" title="3.4 生成会话嵌入"></a>3.4 生成会话嵌入</h3><p>&#8195;&#8195;以前的大多数会话推荐方法假设每一个会话存在不同的用户表征。相反的，SR-GNN模型没有设计任何相关用户表征向量的假设。SR-GNN模型认为一个会话直接被该会话中包含的节点所表示。为了更好的预测用户的下一步点击，通过将会话的长期偏好和当前兴趣结合起来，并将这种组合嵌入作为会话嵌入。</p>
<p>&#8195;&#8195;将所有的会话图输入到门控图神经网络中，得到所有节点的向量，之后将每一个会话表示为一个嵌入向量$s\in R^d$，首先考虑会话啊s的局部嵌入$s_l$。对于一个会话$[v_{s,i},v_{s,2},…,v_{s,n}]$，它的局部嵌入对应与用户最后一次点击物品$v_{s,n}$动作$v_n$，就是说，$s_l=v_n$。</p>
<p>&#8195;&#8195;然后，通过聚集所有节点向量来计算会话图$G_s$的全局嵌入。考虑到这些嵌入的信息会有不同的优先级，我们进一步使用软注意力机制更好地表达全局偏好：<br>$$<br>\alpha_i=q^T\sigma(W_1v_n+W_2v_i+c),\<br>s_g=\sum_{i=1}^n\alpha_iv_i,\tag{6}<br>$$<br>其中，$q\in R^d\ and\ W_1,W_2\in R^{d\times d}$控制物品嵌入向量的权值。最终我们把局部和全局嵌入向量连起来做一次线性变换得到混合嵌入$s_h$:<br>$$<br>s_h=W_3[s_l;s_g]\tag{7}<br>$$<br>其中$W_3\in R^{d\times 2d}$。</p>
<h3 id="3-5-模型训练和做推荐"><a href="#3-5-模型训练和做推荐" class="headerlink" title="3.5 模型训练和做推荐"></a>3.5 模型训练和做推荐</h3><p>&#8195;&#8195;在得到所有会话的嵌入后，我们把所有候选物品$v_i\in V$的嵌入v$_i$和会话表征$s_h$相乘得到该候选物品的得分$\hat{z_i}$，这一段操作定义如下：<br>$$<br>\hat{z_i}=s_h^Tv_i.\tag{8}<br>$$<br>&#8195;&#8195;接下来使用softmax得到预测结果：<br>$$<br>\hat{y}=softmax(\hat{z}),\tag{9}<br>$$<br>&#8195;&#8195;对于每一个会话图，损失函数被定义为预测结果和真实值之间的交叉熵，定义如下：</p>
<p>$$<br>L(\hat{y})=-\sum_{i=1}^m y_i log(\hat{y_i})+(1-y_i)log(1-\hat{y_i}),\tag{10}<br>$$<br>y是one-hot的形式，表示真实值；$\hat{y}$表示每一位表示预测对应一个物品的概率。</p>
<p>最后我们使用Back-Propagation Through Time$(BPTT)$算法来训练SR-GNN模型。</p>
<h2 id="4-实验和分析"><a href="#4-实验和分析" class="headerlink" title="4 实验和分析"></a>4 实验和分析</h2><hr>

<h3 id="4-1-数据集"><a href="#4-1-数据集" class="headerlink" title="4.1 数据集"></a>4.1 数据集</h3><p>&#8195;&#8195;在两个真实数据集Yoochoose和Diginetica评估我们的模型。Yoochoose数据集包含六个月一系列用户在电商网站上点击的数据流。对于Diginetica数据集，我们只使用它的事务数据。</p>
<p>&#8195;&#8195;为了公平起见，我们把所有数据集中长度为1的会话以及会话中物品出现数量小于5的会话全部删除。Yoochoose剩下 7,981,580 个会话和 37,483个物品，而 Diginetica数据集剩下204,771个会话和43097个物品。除此以外，我们通过分割输入序列生成序列以及对应的标签。举个例子，对于一个输入会话序列$s=[v_{s,1},v_{s,2},…,v_{s,n}]$，我们可以通过分割生成一些序列和序列对应的标签$([v_{s,1}],v_{s,2}),([v_{s,1},v_{s,2}],v_{s,3}),…,([v_{s,1},v_{s,2},…,v_{s,n-1}],v_{s,n})$，其中$[v_{s,1},v_{s,2},…,v_{s,n-1}]$是生成的序列，$v_{s,n}$是该序列对应的标签，即用户下一次点击的物品。我们也使用了大量近期的分割1/64,1/4来分割Yoochoose。数据集的统计如Table 1所示。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/gUINes"><img src="https://z3.ax1x.com/2021/05/11/gUINes.jpg" alt="Table 1"></a></p>
<h3 id="4-2-Baseline算法"><a href="#4-2-Baseline算法" class="headerlink" title="4.2 Baseline算法"></a>4.2 Baseline算法</h3><p>&#8195;&#8195;为了评估模型的性能，我们把模型和如下baseline进行实验对比：</p>
<ul>
<li><strong>POP</strong>和<strong>S-POP</strong>分别推荐前N个训练集中和在目前会话中频繁出现的物品。</li>
<li><strong>Item-KNN</strong>推荐与前一次点击物品相似的物品，其中物品的相似度为物品向量的cosine相似度。</li>
<li><strong>BPR-MF</strong>通过随机梯度下降优化一个成对排名目标函数。</li>
<li><strong>FPMC</strong>是基于马尔可夫链的序列预测方法。</li>
<li><strong>GRU4REC</strong>使用RNN对于基于会话的推荐去建模用户序列。</li>
<li><strong>NARM</strong>使用RNN结合attention机制去捕获用户的主要目标以及序列行为。</li>
<li><strong>STAMP</strong>捕获用户对于目前会话大致的兴趣以及对于最后一次点击的兴趣。</li>
</ul>
<h3 id="4-3-评估度量指标"><a href="#4-3-评估度量指标" class="headerlink" title="4.3 评估度量指标"></a>4.3 评估度量指标</h3><ul>
<li><strong>P@20</strong>，Precision是广泛用于评估预测精度的指标。它代表正确预测前20个物品的比例。</li>
<li><strong>MRR@20</strong>，Mean Reciprocal Rank为对预测结果对于真正正确的结果所预测排名的倒数的平均值，当预测的排名大于20，则设置MRR为0，显然MRR值越大性能越好。</li>
</ul>
<h3 id="4-4-与Baseline的对比"><a href="#4-4-与Baseline的对比" class="headerlink" title="4.4 与Baseline的对比"></a>4.4 与Baseline的对比</h3><p>&#8195;&#8195;各模型在P@20和MRR@20指标上的评估数据如Table 2所示，其中最好性能用黑体标出。SR-GNN把分离的回话序列整合到图结构的数据中。在此模型中，我们同时考虑了全局回话偏好和局部偏好。在指标数据中SR-GNN模型的P@20和MRR@20性能是最好的。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/gULUjf"><img src="https://z3.ax1x.com/2021/05/11/gULUjf.jpg" alt="Table 2"></a></p>
<p>&#8195;&#8195;传统的POP和S-POP模型性能相对来说差一些，这些模型只是简单的把推荐当作单独基于重复的共现物品或者联系物品。虽然如此，S-POP的性能依然比POP，BRF-MF和FPMC好，证明了回话上下文信息的重要性。Item-KNN比基于马尔可夫链的FPMC好，注意Item-KNN只利用了物品向量的预先相似度而没有考虑序列信息，这证明了对连续项独立性的假设。</p>
<p>&#8195;&#8195;基于神经网络的方法NARM，STAMP比传统方法的性能好，证明了深度学习非常适合用于该领域问题。长短期记忆模型，如GRU4REC和NARM，使用循环神经元捕获用户大致偏好，而STAMP结合最后一次点击的物品提升模型的短期记忆。这些方法显式地建模用户的全局行为偏好并且考虑用户前面行为和下一次点击的转化，因此比传统方法的性能高出不少。然而它们的性能依然不如SR-GNN。相比于NARM和STAMP，SR-GNN进一步考虑到会话中物品间的转化，因此把所有的回话建模为图结构的数据，这样可以在用户点击中捕获更多复杂和隐式的连接。虽然NARM和GRU4REC显式地建模建模每一个用户并且通过分离的会话序列捕获用户表征，因此可能会忽略物品之间的关联。</p>
<p>&#8195;&#8195;除此以外，SR-GNN采用了soft-attention机制生成会话表征从而自动选择最重要的物品转换并且忽略掉目前会话中不重要的用户行为噪音。相反的，STAMP只用了最后一次点击和之前行为的物品转换，这些条件不够充分。其他的RNN模型，如GRU4REC和NARM，在传播过程中不能选择比较有效的信息，只是使用所有之前的物品获取一个用户大致偏好的向量表征。当用户的行为是无目的的活着他的兴趣在目前会话中发生了360度的变化，传统的模型就不足以应对这种噪音会话。</p>
<h3 id="4-5-与其他连接方案的对比"><a href="#4-5-与其他连接方案的对比" class="headerlink" title="4.5 与其他连接方案的对比"></a>4.5 与其他连接方案的对比</h3><p>&#8195;&#8195;SR-GNN方法把物品之间的连接关系构建为图的结构，因此是非常灵活的。为了评估在每一个会话图中物品之间的关联，我们展示另外两种连接方法的变体。<strong>首先</strong>，我们把所有的会话序列整合建模为一个包含所有物品的有向图，这个图被称为全局图。在全局图中，每一个节点表示一个单独的物品，每一条边表示一个物品向另外一个物品的转换。<strong>第二</strong>，我们在一个会话中用有向图建模物品之间所有的高级关系。总的来说在SR-GNN中有以下两种连接方案：</p>
<ul>
<li>SR-GNN-NGC，使用标准化全局连接的SR-GNN，在全局图中用抽取的边的权重代表图的连接矩阵。</li>
<li>SR-GNN-FC使用全连接来表示所有的高阶关系，其中边的权重为boolean。</li>
</ul>
<p>&#8195;&#8195;不同的连接方法的结果如Figure 3所示。图中看出三种连接方案相比于STAMP和NARM方法有过之无不及，也证实了把会话建模为图结构的好处。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/gaJatK"><img src="https://z3.ax1x.com/2021/05/11/gaJatK.jpg" alt="Figure 3"></a></p>
<p>&#8195;&#8195;相比于SR-GNN，对于每一个会话，SR-GNN-NGC除了考虑当前会话中的物品们还需要考虑了其他会话的影响，这降低了目前会话中高degree节点所连接边的影响。这样一种方法显然影响了目前会话的完整性，特别当图中边的权重不同时会导致性能的下降。</p>
<p>&#8195;&#8195;关于SR-GNN和SR-GNN-FC，前者只建模了连续物品间的关系，而后者进一步把所有的高阶关系看作有向图。从结果上来看，SR-GNN-FC的性能略逊于SR-GNN。这样一个结果表明不是所有的高阶转换可以直接用于物品之间的转换，并且中间的阶段也是必不可少的。比如一个用户浏览网页的顺序为$A \rightarrow B \rightarrow C$，如果直接让A推出C而忽略掉中间的B是非常不合适的。</p>
<h3 id="4-6-与其他会话嵌入方案的对比"><a href="#4-6-与其他会话嵌入方案的对比" class="headerlink" title="4.6 与其他会话嵌入方案的对比"></a>4.6 与其他会话嵌入方案的对比</h3><p>&#8195;&#8195;我们对比了如下三个会话嵌入的方案：</p>
<ul>
<li>SR-GNN-L，只使用局部嵌入。</li>
<li>SR-GNN-AVG，使用平局池化的全局嵌入。</li>
<li>SR-GNN-ATT，使用attention机制的全部嵌入。</li>
</ul>
<p>&#8195;&#8195;实验的结果如Figure 4所示。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/ga0jOO"><img src="https://z3.ax1x.com/2021/05/11/ga0jOO.jpg" alt="Figure 4"></a></p>
<p>&#8195;&#8195;从图中观测到混合嵌入的方法的结果是最好的，这证明了结合目前会话偏好以及全局偏好的重要性。SR-GNN-ATT的性能优于SR-GNN-AVG，表明会话中可能包含一些噪音行为，并且表明attention机制有利于抽取会话中重要的用户行为去构建长期偏好。</p>
<p>&#8195;&#8195;注意SR-GNN-L，依然表现出高于SR-GNN-AVG的性能，与SR-GNN-ATT持平，证明目前会话偏好和长期偏好对于会话推荐都是非常重要的。</p>
<h3 id="4-7-分析会话序列长度"><a href="#4-7-分析会话序列长度" class="headerlink" title="4.7 分析会话序列长度"></a>4.7 分析会话序列长度</h3><p>我们进一步分析不同模型处理不同长度会话的能力。为了对比，我们把Yoochoose的1/64的分割和Diginetica分为”Short”和”Long”两组，其中”Short”表示会话的长度小于等于5，”Long”表示长度大于5。因为5是所有会话平均长度最接近的整数。在Yoochoose数据集中会话短和长分组的比例为0.701和0.299，在Diginetica中分别为0.764和0.236。对于每一种方案，结果数据如Table 3所示。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/ga6z0f"><img src="https://z3.ax1x.com/2021/05/11/ga6z0f.jpg" alt="Table 3"></a></p>
<p>&#8195;&#8195;SR-GNN和他的变体在拥有不同长度会话的数据集中的表现非常稳定。证明了该模型的优越性能以及图神经网络对于会话推荐拥有很强的适应能力。相反的，NARM和STAMP的性能在short和long分组中的表现相差很大，STAMP可以用重复动作来解释此现象，因为使用attention机制，在获取用户表征的时候重复出现的物品将会被忽略。和STAMP类似，NARM在short分组中的表现很好，在long分组中的表现差强人意，因为RNN不擅长处理长序列。</p>
<p>&#8195;&#8195;SR-GNN-L，SR-GNN-ATT和SR-GNN性能优于STAMP和NARM的原因是基于图神经网络学习到更精确的节点向量。这样一种节点嵌入不仅捕获潜在特征并且全局的节点联系。</p>
<h2 id="5-结论"><a href="#5-结论" class="headerlink" title="5 结论"></a>5 结论</h2><hr>

<p>会话推荐是一种用户偏好和历史记录难以获取的重要的推荐系统。这个论文就使用全新的整合图神经网络到表征会话序列的算法架构。提出的方法不仅考虑到会话序列中物品之间复杂的结构和转换，而且发展了一种结合长期偏好和目前会话偏好的策略去更好地预测用户的下一次点击行为。综合的实验结果表明了该模型具有良好的性能。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">TechAoba</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://techaoba.github.io/2021/04/08/ji-yu-hui-hua-de-tu-shen-jing-wang-luo-tui-jian/">http://techaoba.github.io/2021/04/08/ji-yu-hui-hua-de-tu-shen-jing-wang-luo-tui-jian/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://techaoba.github.io" target="_blank">TechAoba的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a><a class="post-meta__tags" href="/tags/%E6%8E%A8%E8%8D%90/">推荐</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/04/21/xian-duan-shu-zhuan-ti/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">线段树专题</div></div></a></div><div class="next-post pull-right"><a href="/2021/04/05/shi-ti-guan-xi-lian-he-chou-qu-de-fen-jie-ce-lue/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">实体关系联合抽取的分解策略</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/06/24/shi-yong-yuan-xue-xi-zai-zhi-shi-tu-pu-zhong-jin-xing-shao-yang-ben-de-lian-jie-yu-ce-ren-wu/" title="使用元学习在知识图谱中进行少样本的链接预测任务"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-24</div><div class="title">使用元学习在知识图谱中进行少样本的链接预测任务</div></div></a></div><div><a href="/2021/05/17/yi-chong-jian-dan-dao-ling-ren-ju-sang-de-shi-ti-guan-xi-chou-qu-fang-fa/" title="一种简单到令人沮丧的实体关系抽取方法"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="title">一种简单到令人沮丧的实体关系抽取方法</div></div></a></div><div><a href="/2021/05/12/shi-ti-guan-xi-lian-he-chou-qu-de-gao-xiao-bian-ma-jie-ma-jia-gou/" title="实体关系联合抽取的高效编码解码架构"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-12</div><div class="title">实体关系联合抽取的高效编码解码架构</div></div></a></div><div><a href="/2021/04/21/pa-lstm-crf-mo-xing-lun-wen/" title="PA-LSTM-CRF模型论文"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-21</div><div class="title">PA-LSTM-CRF模型论文</div></div></a></div><div><a href="/2021/04/05/shi-ti-guan-xi-lian-he-chou-qu-de-fen-jie-ce-lue/" title="实体关系联合抽取的分解策略"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-05</div><div class="title">实体关系联合抽取的分解策略</div></div></a></div><div><a href="/2021/06/15/yuan-xue-xi-zong-shu/" title="元学习综述"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-15</div><div class="title">元学习综述</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">TechAoba</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Session-Based-Recommendation-with-Graph-Neural-Networks"><span class="toc-number">1.</span> <span class="toc-text">Session-Based Recommendation with Graph Neural Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.</span> <span class="toc-text">1 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">1.3.</span> <span class="toc-text">2 相关工作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-SR-GNN%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.4.</span> <span class="toc-text">3 SR-GNN模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%AE%9A%E4%B9%89"><span class="toc-number">1.4.1.</span> <span class="toc-text">3.1 定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%9E%84%E5%BB%BA%E4%BC%9A%E8%AF%9D%E5%9B%BE"><span class="toc-number">1.4.2.</span> <span class="toc-text">3.2 构建会话图</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%9C%A8%E4%BC%9A%E8%AF%9D%E5%9B%BE%E4%B8%AD%E5%AD%A6%E4%B9%A0%E7%89%A9%E5%93%81%E5%B5%8C%E5%85%A5"><span class="toc-number">1.4.3.</span> <span class="toc-text">3.3 在会话图中学习物品嵌入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E7%94%9F%E6%88%90%E4%BC%9A%E8%AF%9D%E5%B5%8C%E5%85%A5"><span class="toc-number">1.4.4.</span> <span class="toc-text">3.4 生成会话嵌入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E5%92%8C%E5%81%9A%E6%8E%A8%E8%8D%90"><span class="toc-number">1.4.5.</span> <span class="toc-text">3.5 模型训练和做推荐</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E5%AE%9E%E9%AA%8C%E5%92%8C%E5%88%86%E6%9E%90"><span class="toc-number">1.5.</span> <span class="toc-text">4 实验和分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.5.1.</span> <span class="toc-text">4.1 数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-Baseline%E7%AE%97%E6%B3%95"><span class="toc-number">1.5.2.</span> <span class="toc-text">4.2 Baseline算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E8%AF%84%E4%BC%B0%E5%BA%A6%E9%87%8F%E6%8C%87%E6%A0%87"><span class="toc-number">1.5.3.</span> <span class="toc-text">4.3 评估度量指标</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-%E4%B8%8EBaseline%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">1.5.4.</span> <span class="toc-text">4.4 与Baseline的对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E4%B8%8E%E5%85%B6%E4%BB%96%E8%BF%9E%E6%8E%A5%E6%96%B9%E6%A1%88%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">1.5.5.</span> <span class="toc-text">4.5 与其他连接方案的对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%E4%B8%8E%E5%85%B6%E4%BB%96%E4%BC%9A%E8%AF%9D%E5%B5%8C%E5%85%A5%E6%96%B9%E6%A1%88%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">1.5.6.</span> <span class="toc-text">4.6 与其他会话嵌入方案的对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-7-%E5%88%86%E6%9E%90%E4%BC%9A%E8%AF%9D%E5%BA%8F%E5%88%97%E9%95%BF%E5%BA%A6"><span class="toc-number">1.5.7.</span> <span class="toc-text">4.7 分析会话序列长度</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E7%BB%93%E8%AE%BA"><span class="toc-number">1.6.</span> <span class="toc-text">5 结论</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/02/23/git-cao-zuo/" title="git操作">git操作</a><time datetime="2022-02-23T07:47:18.000Z" title="发表于 2022-02-23 15:47:18">2022-02-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/12/20/springboot-xue-xi-bi-ji/" title="SpringBoot学习笔记">SpringBoot学习笔记</a><time datetime="2021-12-20T05:43:26.000Z" title="发表于 2021-12-20 13:43:26">2021-12-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/30/kmp-zhuan-ti/" title="KMP专题">KMP专题</a><time datetime="2021-11-30T14:58:55.000Z" title="发表于 2021-11-30 22:58:55">2021-11-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/10/linux-chang-yong-ming-ling/" title="linux常用命令">linux常用命令</a><time datetime="2021-09-10T05:10:03.000Z" title="发表于 2021-09-10 13:10:03">2021-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/10/mongodb-xue-xi-bi-ji/" title="MongoDB学习笔记">MongoDB学习笔记</a><time datetime="2021-09-10T04:23:12.000Z" title="发表于 2021-09-10 12:23:12">2021-09-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By TechAoba</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true,"scale":0.5},"react":{"opacity":0.7,"opacityOnHover":0.8}});</script></body></html>