<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>PA-LSTM-CRF模型论文 | TechAoba的博客</title><meta name="keywords" content="NLP,论文,Relation Extraction,Joint Extraction"><meta name="author" content="TechAoba"><meta name="copyright" content="TechAoba"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling–AAAI 2019摘要  &amp;#8195;&amp;#8195;在这篇论文中提出一种新的统一联合抽取模型，通过询问位置p直接标记该位置的实体以及和该位置实体相关关系和实体的标签。我们首先设计一个标记方案，对于n个单">
<meta property="og:type" content="article">
<meta property="og:title" content="PA-LSTM-CRF模型论文">
<meta property="og:url" content="http://techaoba.github.io/2021/04/21/pa-lstm-crf-mo-xing-lun-wen/index.html">
<meta property="og:site_name" content="TechAoba的博客">
<meta property="og:description" content="Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling–AAAI 2019摘要  &amp;#8195;&amp;#8195;在这篇论文中提出一种新的统一联合抽取模型，通过询问位置p直接标记该位置的实体以及和该位置实体相关关系和实体的标签。我们首先设计一个标记方案，对于n个单">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2021-04-21T06:55:43.000Z">
<meta property="article:modified_time" content="2021-05-04T12:00:40.842Z">
<meta property="article:author" content="TechAoba">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="论文">
<meta property="article:tag" content="Relation Extraction">
<meta property="article:tag" content="Joint Extraction">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://techaoba.github.io/2021/04/21/pa-lstm-crf-mo-xing-lun-wen/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'PA-LSTM-CRF模型论文',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-05-04 20:00:40'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="TechAoba的博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">TechAoba的博客</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">PA-LSTM-CRF模型论文</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-04-21T06:55:43.000Z" title="发表于 2021-04-21 14:55:43">2021-04-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-05-04T12:00:40.842Z" title="更新于 2021-05-04 20:00:40">2021-05-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="PA-LSTM-CRF模型论文"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Joint-Extraction-of-Entities-and-Overlapping-Relations-Using-Position-Attentive-Sequence-Labeling–AAAI-2019"><a href="#Joint-Extraction-of-Entities-and-Overlapping-Relations-Using-Position-Attentive-Sequence-Labeling–AAAI-2019" class="headerlink" title="Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling–AAAI 2019"></a>Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling–AAAI 2019</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><hr>

<p>&#8195;&#8195;在这篇论文中提出一种新的统一联合抽取模型，通过询问位置p直接标记该位置的实体以及和该位置实体相关关系和实体的标签。我们首先设计一个标记方案，对于n个单词的句子生成n个标记序列。然后设计了<strong>postition-attention mechanism</strong>–位置注意力机制，对于每一个查询位置p生成不同的句子表征，从而建模这n个标记序列。通过这种方法，可以同时抽取所有实体及其类型，以及重叠关系。实验表明，我们的模型在抽取重叠关系以及长距离关系任务有良好表现，并且在两个公共数据集上取得了最先进的性能。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/cbssAO"><img src="https://z3.ax1x.com/2021/04/21/cbssAO.jpg" alt="Figure 1"></a></p>
<h2 id="1-介绍"><a href="#1-介绍" class="headerlink" title="1 介绍"></a>1 介绍</h2><hr>

<p>&#8195;&#8195;RE$(Relation\ Extraction)$任务旨在检测非结构话文本实体间的语义关系。传统的RE方法把<strong>实体检测子任务</strong>和<strong>实体间的关系分类子任务</strong>作为pipeline的形式完成。这样的方法虽然容易实现，但是它忽视了两个子任务之间隐藏的依赖关系和错误传播的影响。</p>
<p>&#8195;&#8195;不同于pipeline方法，joint extraction方法使用一个联合模型同时完成这两个子任务。最近的研究也展现出joint extraction模型的优势，即可以高效地整合实体信息和关系信息，因此在两个子任务上都展示出良好表现。以往的联合模型大多是基于特征的结构化学习，这些方法很大程度上依赖于手工构建的特性和其他NLP工具包。近年来，已有多种神经网络结构被应用，它们大多利用参数共享进行联合建模。仍需要显式的独立分量来进行实体识别和关系分类。相对的，Zheng et al. 提出了一种特殊的标注方案，将联合提取转化为序列标注问题，统一求解。但是模型不能识别重叠关系，这可能会导致在处理具有重叠关系的句子时召回率较低。Zeng et al. (2018)采用带复制机制的序列到序列学习。虽然解决了重叠关系抽取，但改模型无法识别multi-word实体。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/cbsbCQ"><img src="https://z3.ax1x.com/2021/04/21/cbsbCQ.jpg" alt="Figure 2"></a></p>
<p>&#8195;&#8195;在该论文中，提出了一种新的统一方法，根据查询位置p的词同时标注实体和关系标签来解决联合抽取问题。给定一个句子和询问位置p，我们的模型需要回答两个伪问题：1. 位置p处的实体和它的类型是什么。2. 哪些实体和p处实体有关。为此，本文设计了特殊的标记方案，即在位置p处标记实体标签，然后在其他位置标记关系标签$(see\ Figure\ 2)$。因此，实际上把联合抽取问题转化为一系列的序列标注问题。就是说，对于n个单词的句子，对其进行n次序列标注。为了在一个统一的模型中对句子的n个标记序列进行建模，在序列标记模型中引入了一种新的位置注意机制$(see\ Figure\ 3)$，以产生n种不同的位置感知句子表征。然后这些表征用于解码不同的标记结果，从这些标记结构中可以获取实体及其类型以及重叠关系，此外提出的注意力机制可以建立长距离单词间的连接，继而得到长距离关系。</p>
<p><strong>Contributions：</strong></p>
<ul>
<li><p>设计了一个能够同时表示实体类型和重叠关系的标记方案。</p>
</li>
<li><p>提出了一种位置注意机制，根据查询位置p产生不同的位置感知句子表示，用于解码不同的标记序列和提取重叠关系。</p>
</li>
<li><p>用两个公共数据集证明了该方法的有效性，并取得了最新的结果。此外，分析表明，本文的模型在提取长距离关系方面表现出更好的性能，这通常是比较困难的。</p>
</li>
</ul>
<h2 id="2-方法"><a href="#2-方法" class="headerlink" title="2. 方法"></a>2. 方法</h2><hr>

<h3 id="2-1-标记方案"><a href="#2-1-标记方案" class="headerlink" title="2.1 标记方案"></a>2.1 标记方案</h3><p>&#8195;&#8195;在Figure 2中，基于模型标记方案，根据不同的询问位置p标记了n个不同的标记序列。在每一个标记序列中，如果位置p是一个实体的开始位置则会在位置p标记该实体的类型，并且同时在和该实体有关系的实体位置标记上对应关系的tag。除此以外的位置被标记为“O”$(Outside)$。这样的话三元组就可以通过标记序列完成抽取任务。显然，通过这种标记方法可以抽取重叠关系。对于所有的实体和关系类型使用“BIES”$(Begin,Inside,End,Single)$标记，这样能够抽取multi-word实体。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/cbWlRS"><img src="https://z3.ax1x.com/2021/04/21/cbWlRS.png" alt="Figure 3"></a></p>
<h3 id="2-2-结合位置注意力机制的端到端的列表标记模型"><a href="#2-2-结合位置注意力机制的端到端的列表标记模型" class="headerlink" title="2.2 结合位置注意力机制的端到端的列表标记模型"></a>2.2 结合位置注意力机制的端到端的列表标记模型</h3><p>&#8195;&#8195;使用本文的标记方案，构建了一个端到端序列标记神经体系结构$(Figure 3)$，以联合提取实体和重叠关系。首先使用RNN编码器把n-word句子进行编码。然后，使用位置注意力机制为每个查询位置p生成不同的位置感知句子表示；基于这些位置感知表示，最后使用条件随机场$(CRF)$对n个标签序列进行解码，以提取实体和重叠关系。</p>
<h4 id="2-2-1-Bi-LSTM-Encoder"><a href="#2-2-1-Bi-LSTM-Encoder" class="headerlink" title="2.2.1 Bi-LSTM Encoder"></a>2.2.1 <strong>Bi-LSTM Encoder</strong></h4><p>&#8195;&#8195;RNNs已经被证明有强大的捕获输入序列单词间依赖的能力。在模型中，使用了Bidirectional Long Short Term Memory$(Bi-LSTM)$作为RNN。对于句子中的单词表征，使用了单词的词嵌入$w_t^w$以及字符级$w_t^c$嵌入，其中字符级嵌入可以捕获单词形态学上的特征。最终的单词表征为二者的拼接$[w_t^w;w_t^c]$。接下来，Bi-LSTM计算向前和向后方向上的状态。</p>
<p><a target="_blank" rel="noopener" href="https://imgtu.com/i/cbo2od"><img src="https://z3.ax1x.com/2021/04/21/cbo2od.jpg"></a></p>
<h4 id="2-2-2-Position-Attention-Mechanism"><a href="#2-2-2-Position-Attention-Mechanism" class="headerlink" title="2.2.2 Position-Attention Mechanism"></a>2.2.2 <strong>Position-Attention Mechanism</strong></h4><p>&#8195;&#8195; 抽取实体和其他实体之间关系的关键信息包含：</p>
<ol>
<li>该实体中的其他单词。</li>
<li>相依赖的实体。</li>
<li>表示依赖关系的上下文。</li>
</ol>
<p>&#8195;&#8195;基于这些考虑，提出位置注意力机制，它可以把询问位置的实体信息和句子中的上下文信息进行编码，生成位置感知和上下文感知表征$u_{t=1}^n$为:<br>$$<br>u_t=[h_t;c_t]\tag{3}<br>$$<br>其中$c_t=att(H,h_p,h_t)$是句子的注意力池化向量。<br>$$<br>s_{tj}=v^T tanh(W^H h_j+W^p h_p+W^h h_t)\\<br>a_{tj}= \frac{exp(s_{tj})}{ \sum_{k=1}^n exp(s_{tk})}\\<br>c_t=\sum_{t=1}^na_{tj}h_j\tag{4}<br>$$<br>其中$W^H,W^p,W^h,v$都是学习的参数，$h_j,h_p,h_t$分别为j，p，t位置通过Bi-LSTM求得的隐藏状态，$s_{tj}$是在每一个位置进行迭代的与p，t位置计算的一个相对分数，$a_{tj}$是$s_{tj}$进行归一化的注意力权重。笔者注$(自洽的说法)$：<strong>这里的j、p、t可以这样理解，p表示头实体的表征，t表示计算t位置实体与p头实体的关系，而在公式中迭代的j表示把句子中所有h与p和t进行对比计算求得各个位置的权重，求得的加权即为p头实体和t尾实体之间关系在上下文中所能够收集的隐藏信息。</strong></p>
<h4 id="2-2-3-CRF-Decoder"><a href="#2-2-3-CRF-Decoder" class="headerlink" title="2.2.3 CRF Decoder"></a>2.2.3 CRF Decoder</h4><p>&#8195;&#8195; 对于序列标注模型，同时考虑相邻标签和联合解码标签链是非常有必要的。因此，相对于独立解码每一个标签，模型采用条件随机场$(CRF)$进行联合解码。定义$Z= z_{t=1}^n$为输入序列分数，其中$z_t$是由位置感知的句子表征$u_t$计算得到：<br>$$<br>z_t=W^u u_t\tag{5}<br>$$<br>&#8195;&#8195; 其中$z_t \in R^{N_t}$为第t个单词的标记分数，$N_t$是标记分类的数量。定义$Z_{t,j}$为把位置t标记为第j个标签的分数。对于序列标签$\textbf{y} =  y_{t=1}^n$，定义解码标签的分数为:<br>$$<br>score(Z,y)=\sum^n_{t=0} A_{y_t,y_{t+1}} + \sum^n_{t=1} Z_{t,y_t}\tag{6}<br>$$<br>&#8195;&#8195; 其中，A矩阵式转移矩阵，$A_{i,j}$表示i标签转换为j标签的转移分数。接下来我们得到所有可能标签序列$\textbf{y}$的条件概率：<br>$$<br>p(y|Z)=\frac{exp(score(Z,y))}{\sum_{y’ \in Y_z} exp(score(Z,y’))}\tag{7}<br>$$<br>&#8195;&#8195; 其中，$Y_z$表示Z下所有可能的标记序列，在训练的过程中，会在训练集中最大化正确标记序列的对数似然：<br>$$<br>L=\sum_{i} \log{p(y|Z)}\tag{8}<br>$$<br>解码过程就是最大得分的标记序列：<br>$$<br>y’=argmax\ _{y \in Y_Z}\ score(Z,y)\tag{9}<br>$$</p>
<h4 id="2-2-4-Extracting-Entities-and-Overlapping-Relationsfrom-Tag-Sequences"><a href="#2-2-4-Extracting-Entities-and-Overlapping-Relationsfrom-Tag-Sequences" class="headerlink" title="2.2.4 Extracting Entities and Overlapping Relationsfrom Tag Sequences"></a>2.2.4 Extracting Entities and Overlapping Relationsfrom Tag Sequences</h4><p>&#8195;&#8195; 在标记方案中，三元组的头实体和它的实体类型可以从对应的询问位置的标记结果中得到。如果存在对应的实体，则在其他的对应位置会标记出它们之间的标记类型。重叠关系的抽取也因为一个实体可以在一次标记任务中对应多个实体关系而得以解决。<strong>除此以外，抽取的实体类型可以用于验证三元组，比如若关系是Born_in，那么三元组的第一个单词一定是PERSON。</strong></p>
<h2 id="3-实验"><a href="#3-实验" class="headerlink" title="3. 实验"></a>3. 实验</h2><hr>















</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">TechAoba</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://techaoba.github.io/2021/04/21/pa-lstm-crf-mo-xing-lun-wen/">http://techaoba.github.io/2021/04/21/pa-lstm-crf-mo-xing-lun-wen/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://techaoba.github.io" target="_blank">TechAoba的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP</a><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a><a class="post-meta__tags" href="/tags/Relation-Extraction/">Relation Extraction</a><a class="post-meta__tags" href="/tags/Joint-Extraction/">Joint Extraction</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/04/23/codeforces-717-div2-ti-jie/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">codeforces 717 div2 题解</div></div></a></div><div class="next-post pull-right"><a href="/2021/04/21/xian-duan-shu-zhuan-ti/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">线段树专题</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/04/05/shi-ti-guan-xi-lian-he-chou-qu-de-fen-jie-ce-lue/" title="实体关系联合抽取的分解策略"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-05</div><div class="title">实体关系联合抽取的分解策略</div></div></a></div><div><a href="/2021/06/24/shi-yong-yuan-xue-xi-zai-zhi-shi-tu-pu-zhong-jin-xing-shao-yang-ben-de-lian-jie-yu-ce-ren-wu/" title="使用元学习在知识图谱中进行少样本的链接预测任务"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-24</div><div class="title">使用元学习在知识图谱中进行少样本的链接预测任务</div></div></a></div><div><a href="/2021/05/17/yi-chong-jian-dan-dao-ling-ren-ju-sang-de-shi-ti-guan-xi-chou-qu-fang-fa/" title="一种简单到令人沮丧的实体关系抽取方法"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-17</div><div class="title">一种简单到令人沮丧的实体关系抽取方法</div></div></a></div><div><a href="/2021/05/12/shi-ti-guan-xi-lian-he-chou-qu-de-gao-xiao-bian-ma-jie-ma-jia-gou/" title="实体关系联合抽取的高效编码解码架构"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-12</div><div class="title">实体关系联合抽取的高效编码解码架构</div></div></a></div><div><a href="/2021/04/08/ji-yu-hui-hua-de-tu-shen-jing-wang-luo-tui-jian/" title="基于会话的图神经网络推荐"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-04-08</div><div class="title">基于会话的图神经网络推荐</div></div></a></div><div><a href="/2021/06/15/yuan-xue-xi-zong-shu/" title="元学习综述"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-06-15</div><div class="title">元学习综述</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">TechAoba</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Joint-Extraction-of-Entities-and-Overlapping-Relations-Using-Position-Attentive-Sequence-Labeling%E2%80%93AAAI-2019"><span class="toc-number">1.</span> <span class="toc-text">Joint Extraction of Entities and Overlapping Relations Using Position-Attentive Sequence Labeling–AAAI 2019</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.</span> <span class="toc-text">1 介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%96%B9%E6%B3%95"><span class="toc-number">1.3.</span> <span class="toc-text">2. 方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%A0%87%E8%AE%B0%E6%96%B9%E6%A1%88"><span class="toc-number">1.3.1.</span> <span class="toc-text">2.1 标记方案</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E7%BB%93%E5%90%88%E4%BD%8D%E7%BD%AE%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6%E7%9A%84%E7%AB%AF%E5%88%B0%E7%AB%AF%E7%9A%84%E5%88%97%E8%A1%A8%E6%A0%87%E8%AE%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.2 结合位置注意力机制的端到端的列表标记模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-1-Bi-LSTM-Encoder"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">2.2.1 Bi-LSTM Encoder</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-2-Position-Attention-Mechanism"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">2.2.2 Position-Attention Mechanism</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-3-CRF-Decoder"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">2.2.3 CRF Decoder</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-4-Extracting-Entities-and-Overlapping-Relationsfrom-Tag-Sequences"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">2.2.4 Extracting Entities and Overlapping Relationsfrom Tag Sequences</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%AE%9E%E9%AA%8C"><span class="toc-number">1.4.</span> <span class="toc-text">3. 实验</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/02/23/git-cao-zuo/" title="git操作">git操作</a><time datetime="2022-02-23T07:47:18.000Z" title="发表于 2022-02-23 15:47:18">2022-02-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/12/20/springboot-xue-xi-bi-ji/" title="SpringBoot学习笔记">SpringBoot学习笔记</a><time datetime="2021-12-20T05:43:26.000Z" title="发表于 2021-12-20 13:43:26">2021-12-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/30/kmp-zhuan-ti/" title="KMP专题">KMP专题</a><time datetime="2021-11-30T14:58:55.000Z" title="发表于 2021-11-30 22:58:55">2021-11-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/10/linux-chang-yong-ming-ling/" title="linux常用命令">linux常用命令</a><time datetime="2021-09-10T05:10:03.000Z" title="发表于 2021-09-10 13:10:03">2021-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/10/mongodb-xue-xi-bi-ji/" title="MongoDB学习笔记">MongoDB学习笔记</a><time datetime="2021-09-10T04:23:12.000Z" title="发表于 2021-09-10 12:23:12">2021-09-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By TechAoba</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true,"scale":0.5},"react":{"opacity":0.7,"opacityOnHover":0.8}});</script></body></html>