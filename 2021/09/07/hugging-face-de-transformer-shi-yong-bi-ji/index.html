<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>hugging face的Transformer使用笔记 | TechAoba的博客</title><meta name="keywords" content="学习笔记,huggingface,Transformer,算法API"><meta name="author" content="TechAoba"><meta name="copyright" content="TechAoba"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="huggingface的Transformer学习笔记1. 快速入门之pipeline首先需要在conda环境中安装最新版的transformers包pip install -U transformers。 1.1 快速情感分析现在我们开始使用transformers中的pipeline完成情感分析任务吧！ from transformers import pipeline  classifier">
<meta property="og:type" content="article">
<meta property="og:title" content="hugging face的Transformer使用笔记">
<meta property="og:url" content="http://techaoba.github.io/2021/09/07/hugging-face-de-transformer-shi-yong-bi-ji/index.html">
<meta property="og:site_name" content="TechAoba的博客">
<meta property="og:description" content="huggingface的Transformer学习笔记1. 快速入门之pipeline首先需要在conda环境中安装最新版的transformers包pip install -U transformers。 1.1 快速情感分析现在我们开始使用transformers中的pipeline完成情感分析任务吧！ from transformers import pipeline  classifier">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2021-09-07T05:35:06.000Z">
<meta property="article:modified_time" content="2021-09-08T08:49:47.105Z">
<meta property="article:author" content="TechAoba">
<meta property="article:tag" content="学习笔记">
<meta property="article:tag" content="huggingface">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="算法API">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://techaoba.github.io/2021/09/07/hugging-face-de-transformer-shi-yong-bi-ji/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'hugging face的Transformer使用笔记',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-09-08 16:49:47'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"><link rel="alternate" href="/atom.xml" title="TechAoba的博客" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<link rel="stylesheet" href="/css/prism-line-numbers.css" type="text/css"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">TechAoba的博客</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">hugging face的Transformer使用笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-09-07T05:35:06.000Z" title="发表于 2021-09-07 13:35:06">2021-09-07</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-09-08T08:49:47.105Z" title="更新于 2021-09-08 16:49:47">2021-09-08</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="hugging face的Transformer使用笔记"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="huggingface的Transformer学习笔记"><a href="#huggingface的Transformer学习笔记" class="headerlink" title="huggingface的Transformer学习笔记"></a>huggingface的Transformer学习笔记</h1><h2 id="1-快速入门之pipeline"><a href="#1-快速入门之pipeline" class="headerlink" title="1. 快速入门之pipeline"></a>1. 快速入门之pipeline</h2><p>首先需要在conda环境中安装最新版的transformers包<code>pip install -U transformers</code>。</p>
<h3 id="1-1-快速情感分析"><a href="#1-1-快速情感分析" class="headerlink" title="1.1 快速情感分析"></a>1.1 快速情感分析</h3><p>现在我们开始使用transformers中的pipeline完成情感分析任务吧！</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline

classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"sentiment-analysis"</span><span class="token punctuation">)</span>
results <span class="token operator">=</span> classifier<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"We are very sad to show you the Transformers library."</span><span class="token punctuation">,</span> <span class="token string">"We hope you don't hate it."</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> result <span class="token keyword">in</span> results<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"label: {result['label']}, with score: {round(result['score'], 4)}"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english</span>
<span class="token comment" spellcheck="true"># label: NEGATIVE, with score: 0.9985</span>
<span class="token comment" spellcheck="true"># label: NEGATIVE, with score: 0.5309</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以发现，huggingface的API使用起来还是非常方便的。在pipeline中指定任务类型是”sentiment-analysis”，在分类器中输入分类的句子便可以得到分类结果。</p>
<p>但这种方式会通过网络缓存情感分析任务的默认模型，在下一次使用的时候依然可能需要重新缓存，非常不方便。</p>
<h3 id="1-2-调用本地模型"><a href="#1-2-调用本地模型" class="headerlink" title="1.2 调用本地模型"></a>1.2 调用本地模型</h3><p>可以在<a target="_blank" rel="noopener" href="https://huggingface.co/models">huggingface模型仓库</a>中选择合适的模型进行相关的任务。比如情感分析的默认模型distilbert-base-uncased-finetuned-sst-2-english，或者bert-base-multilingual-uncased-sentiment模型也可用于情感分析任务。</p>
<pre class="line-numbers language-bash"><code class="language-bash"><span class="token comment" spellcheck="true"># 注意lfs一定要安装，安装后才能使用git下载大文件</span>
$ <span class="token function">git</span> lfs <span class="token function">install</span>
$ <span class="token function">git</span> clone https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english

<span class="token comment" spellcheck="true"># 或者安装bert-base-multilingual-uncased-sentiment模型</span>
$ <span class="token function">git</span> clone https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这里在本地使用git下载了模型。下面是调用本地模型的写法：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline<span class="token punctuation">,</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification

<span class="token comment" spellcheck="true"># 模型的地址</span>
model_dir <span class="token operator">=</span> <span class="token string">"../BERT_DIR/bert-base-multilingual-uncased-sentiment"</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>
classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"sentiment-analysis"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model_dir<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>

results <span class="token operator">=</span> classifier<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"We are very happy to show you the Transformers library."</span><span class="token punctuation">,</span> <span class="token string">"We hope you don't hate it."</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> result <span class="token keyword">in</span> results<span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"label: {result['label']}, with score: {round(result['score'], 4)}"</span><span class="token punctuation">)</span>
    
<span class="token comment" spellcheck="true"># label: 5 stars, with score: 0.7496</span>
<span class="token comment" spellcheck="true"># label: 5 stars, with score: 0.2365</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以发现两个模型虽然都是用于情感分类，但是output所呈现的格式有所不同。</p>
<p>上一个分类的label为POSITIVE和NEGATIVE，score是对应的置信度。而第二个分为了五个级别，星级越高表示越乐观。</p>
<p>huggingface中除了用于情感分类任务的模型外还有其他有趣的模型，比如Zero-Shot Classification模型对于用于自定义的labels进行分类预测，这里下载模型<code>git clone https://huggingface.co/typeform/distilbert-base-uncased-mnli</code>。</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> pipeline<span class="token punctuation">,</span> AutoTokenizer<span class="token punctuation">,</span> AutoModelForSequenceClassification

model_dir <span class="token operator">=</span> <span class="token string">"../BERT_DIR/distilbert-base-uncased-mnli"</span>
tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>
model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>
classifier <span class="token operator">=</span> pipeline<span class="token punctuation">(</span><span class="token string">"zero-shot-classification"</span><span class="token punctuation">,</span> model<span class="token operator">=</span>model<span class="token punctuation">,</span> tokenizer<span class="token operator">=</span>tokenizer<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>classifier<span class="token punctuation">(</span><span class="token string">"Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app."</span><span class="token punctuation">,</span>
           candidate_labels<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"mobile"</span><span class="token punctuation">,</span> <span class="token string">"website"</span><span class="token punctuation">,</span> <span class="token string">"billing"</span><span class="token punctuation">,</span> <span class="token string">"account access"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># {'sequence': 'Last week I upgraded my iOS version and ever since then my phone has been overheating whenever I use your app.', </span>
<span class="token comment" spellcheck="true"># 'labels': ['mobile', 'billing', 'account access', 'website'], </span>
<span class="token comment" spellcheck="true"># 'scores': [0.6334261298179626, 0.13391011953353882, 0.12124086916446686, 0.1114228144288063]}</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>huggingface中对于一种预训练任务有多种模型，模型大小也在一定程度上决定了模型的性能。</p>
<h3 id="1-3-Tokenizer的使用"><a href="#1-3-Tokenizer的使用" class="headerlink" title="1.3 Tokenizer的使用"></a>1.3 Tokenizer的使用</h3><p>Tokenizer实际上是单词token和序号之间的映射字典。</p>
<pre class="line-numbers language-python"><code class="language-python">tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>
inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token string">"We are very happy to show you the Transformers library."</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># {'input_ids': [101, 1284, 1132, 1304, 2816, 1106, 1437, 1128, 1103, 25267, 3340, 119, 102],</span>
<span class="token comment" spellcheck="true"># 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],</span>
<span class="token comment" spellcheck="true"># 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>在实际使用中会出现一次输入一个batch数据的情况。这时候我们希望batch中句子的长度保持一致（使用padding）；同时希望能尽量少的padding，达到batch中的最大长度以及不超过bert模型所能够支持的最大长度512。</p>
<pre class="line-numbers language-python"><code class="language-python">pt_batch <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>
    <span class="token punctuation">[</span><span class="token string">"We are very happy to show you the Transformers library."</span><span class="token punctuation">,</span> <span class="token string">"We hope you don't hate it."</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
    max_length<span class="token operator">=</span><span class="token number">512</span><span class="token punctuation">,</span>
    return_tensors<span class="token operator">=</span><span class="token string">"pt"</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">for</span> key<span class="token punctuation">,</span> value <span class="token keyword">in</span> pt_batch<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"{key}: {value.numpy().tolist()}"</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># input_ids: [[101, 1284, 1132, 1304, 2816, 1106, 1437, 1128, 1103, 25267, 3340, 119, 102], [101, 1284, 2810, 1128, 1274, 112, 189, 4819, 1122, 119, 102, 0, 0]]</span>
<span class="token comment" spellcheck="true"># token_type_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]</span>
<span class="token comment" spellcheck="true"># attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="1-4-model的使用"><a href="#1-4-model的使用" class="headerlink" title="1.4 model的使用"></a>1.4 model的使用</h3><p>在对句子进行tokenizer预处理以后，则可以把值传给model了。</p>
<pre class="line-numbers language-python"><code class="language-python">pt_model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>
pt_outputs <span class="token operator">=</span> pt_model<span class="token punctuation">(</span><span class="token operator">**</span>pt_batch<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pt_outputs<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># SequenceClassifierOutput(loss=None, logits=tensor([[-2.6407, -2.7451, -0.8407,  2.0394,  3.2070],</span>
<span class="token comment" spellcheck="true">#         [ 0.0064, -0.1258, -0.0503, -0.1655,  0.1329]],</span>
<span class="token comment" spellcheck="true">#        grad_fn=&lt;AddmmBackward>), hidden_states=None, attentions=None)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>注意现在还是logits数据，我们需要最后的激活函数，如SoftMax：</p>
<pre class="line-numbers language-python"><code class="language-python">pt_predictions <span class="token operator">=</span> nn<span class="token punctuation">.</span>functional<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>pt_outputs<span class="token punctuation">.</span>logits<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pt_predictions<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># tensor([[0.0022, 0.0019, 0.0131, 0.2332, 0.7496],</span>
<span class="token comment" spellcheck="true">#         [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=&lt;SoftmaxBackward>)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>可以发现0.7496和0.2365即之前score的数值。</p>
<p>如果在模型输入的同时输入目标标签，输出会包含一个loss值：</p>
<pre class="line-numbers language-python"><code class="language-python">pt_model <span class="token operator">=</span> AutoModelForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span>model_dir<span class="token punctuation">)</span>
pt_outputs <span class="token operator">=</span> pt_model<span class="token punctuation">(</span><span class="token operator">**</span>pt_batch<span class="token punctuation">,</span> labels<span class="token operator">=</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>pt_outputs<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># SequenceClassifierOutput(loss=tensor(0.8650, grad_fn=&lt;NllLossBackward>), logits=tensor([[-2.6407, -2.7451, -0.8407,  2.0394,  3.2070],</span>
<span class="token comment" spellcheck="true">#         [ 0.0064, -0.1258, -0.0503, -0.1655,  0.1329]],</span>
<span class="token comment" spellcheck="true">#        grad_fn=&lt;AddmmBackward>), hidden_states=None, attentions=None)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>一旦模型微调好，可以使用一下方式保存模型：</p>
<pre class="line-numbers language-python"><code class="language-python">tokenizer<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>save_directory<span class="token punctuation">)</span>
model<span class="token punctuation">.</span>save_pretrained<span class="token punctuation">(</span>save_directory<span class="token punctuation">)</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<h2 id="2-术语"><a href="#2-术语" class="headerlink" title="2. 术语"></a>2. 术语</h2><h3 id="2-1-模型输入"><a href="#2-1-模型输入" class="headerlink" title="2.1 模型输入"></a>2.1 模型输入</h3><p>通常情况下模型只需要ids作为输入参数。ids是token的序号，换句话说是序列的数字表征。每个模型的tokenizer工作不同但是底层的机制是一模一样的，下面是BERT模型的tokenizer，可以用来分词：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizer

tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">"../BERT_DIR/bert-base-cased"</span><span class="token punctuation">)</span>
sequence <span class="token operator">=</span> <span class="token string">"A Titan RTX has 24GB of VRAM"</span>

tokenized_sequence <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>tokenize<span class="token punctuation">(</span>sequence<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>tokenized_sequence<span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># ['A', 'Titan', 'R', '##T', '##X', 'has', '24', '##GB', 'of', 'V', '##RA', '##M']</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>tokenizer负责将序列划分为词汇表中可用的token。划分为的token要么为单词，要么为子词。比如VRAM将被划分为”V”, “RA”和”M”，但为了区分单词和子词，子词前加了双#前缀。这些token之后会以模型的规则转化为IDs。</p>
<p>而实际上这两步可以化作一步，直接喂入句子序列完成序列和ids的转化。</p>
<p><code>inputs = tokenizer(sequence)</code></p>
<pre class="line-numbers language-python"><code class="language-python">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>sequence<span class="token punctuation">)</span>
encoded_sequence <span class="token operator">=</span> inputs<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_sequence<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># [101, 138, 18696, 155, 1942, 3190, 1144, 1572, 13745, 1104, 159, 9664, 2107, 102]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>在编码序列中自动加入了special token，如101表示分类器[CLS]，102表示分隔符[SEP]。</p>
<p>现在对encode序列进行解码：</p>
<pre class="line-numbers language-python"><code class="language-python">decoded_sequence <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoded_sequence<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>decoded_sequence<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># [CLS] A Titan RTX has 24GB of VRAM [SEP]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h3 id="2-2-Attention-mask"><a href="#2-2-Attention-mask" class="headerlink" title="2.2 Attention mask"></a>2.2 Attention mask</h3><p>注意力掩码是在序列进行批处理时的一个可选参数。该参数表明了模型中哪些参数将会参与运算。现在考虑一下两个序列：</p>
<pre class="line-numbers language-python"><code class="language-python">sequence_a <span class="token operator">=</span> <span class="token string">"This is a short sequence."</span>
sequence_b <span class="token operator">=</span> <span class="token string">"This is a rather long sequence. It is at least longer than the sequence A."</span>
encoded_sequence_a <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>sequence_a<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
encoded_sequence_b <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>sequence_b<span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>len<span class="token punctuation">(</span>encoded_sequence_a<span class="token punctuation">)</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>encoded_sequence_b<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 8 19</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>发现两个序列的长度不一致，因此它们并不能放在同一个tensor当中。第一个序列需要扩充到与第二和序列长度为止，或者反过来对第二个序列进行截取。</p>
<p>在tokenizer中设置padding为True即可对序列进行填充：</p>
<pre class="line-numbers language-python"><code class="language-python">encoded_sequence_padding <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span><span class="token punctuation">[</span>sequence_a<span class="token punctuation">,</span> sequence_b<span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>encoded_sequence_padding<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> encoded_sequence_padding<span class="token punctuation">[</span><span class="token string">"attention_mask"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># [[101, 1188, 1110, 170, 1603, 4954, 119, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], </span>
<span class="token comment" spellcheck="true"># [101, 1188, 1110, 170, 1897, 1263, 4954, 119, 1135, 1110, 1120, 1655, 2039, 1190, 1103, 4954, 138, 119, 102]]</span>
<span class="token comment" spellcheck="true"># [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], </span>
<span class="token comment" spellcheck="true"># [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="2-3-Token-Type-IDs"><a href="#2-3-Token-Type-IDs" class="headerlink" title="2.3 Token Type IDs"></a>2.3 Token Type IDs</h3><p>有些模型会在一对句子上做分类任务，或者做问答任务时把文本和问题拼凑在一起。这时需要两个序列都会加入一个“input_ids”当中，而此时需要special token，CLS和SEP对句子进行划分。把两个序列作两个参数喂入tokenizer中（而不是list的方式）如下：</p>
<pre class="line-numbers language-python"><code class="language-python">sequence_a <span class="token operator">=</span> <span class="token string">"HuggingFace is based in NYC"</span>
sequence_b <span class="token operator">=</span> <span class="token string">"Where is HuggingFace based?"</span>

encoded_dict <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>sequence_a<span class="token punctuation">,</span> sequence_b<span class="token punctuation">)</span>
decoded <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>encoded_dict<span class="token punctuation">[</span><span class="token string">"input_ids"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>decoded<span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># [CLS] HuggingFace is based in NYC [SEP] Where is HuggingFace based? [SEP]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>这样模型便知道序列的开始和结束位置。然而，有些模型（如bert）依然会使用token_type_ids来对两个不同的序列进行mask。如下：</p>
<pre class="line-numbers language-python"><code class="language-python"><span class="token keyword">print</span><span class="token punctuation">(</span>encoded_dict<span class="token punctuation">[</span><span class="token string">'token_type_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]</span>
<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">TechAoba</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://techaoba.github.io/2021/09/07/hugging-face-de-transformer-shi-yong-bi-ji/">http://techaoba.github.io/2021/09/07/hugging-face-de-transformer-shi-yong-bi-ji/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://techaoba.github.io" target="_blank">TechAoba的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">学习笔记</a><a class="post-meta__tags" href="/tags/huggingface/">huggingface</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a><a class="post-meta__tags" href="/tags/%E7%AE%97%E6%B3%95API/">算法API</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/09/10/mongodb-xue-xi-bi-ji/"><img class="prev-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">MongoDB学习笔记</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/24/da-jian-shi-yan-shi-yuan-cheng-ji-qi-xue-xi-huan-jing/"><img class="next-cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">搭建实验室远程机器学习环境</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/07/31/mybatis-xue-xi/" title="MyBatis学习"><img class="cover" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-07-31</div><div class="title">MyBatis学习</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">TechAoba</div><div class="author-info__description"></div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">25</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">39</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#huggingface%E7%9A%84Transformer%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">huggingface的Transformer学习笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E4%B9%8Bpipeline"><span class="toc-number">1.1.</span> <span class="toc-text">1. 快速入门之pipeline</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E5%BF%AB%E9%80%9F%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 快速情感分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E8%B0%83%E7%94%A8%E6%9C%AC%E5%9C%B0%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 调用本地模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Tokenizer%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 Tokenizer的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-4-model%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4 model的使用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E6%9C%AF%E8%AF%AD"><span class="toc-number">1.2.</span> <span class="toc-text">2. 术语</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%A8%A1%E5%9E%8B%E8%BE%93%E5%85%A5"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 模型输入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-Attention-mask"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 Attention mask</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-Token-Type-IDs"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 Token Type IDs</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2022/02/23/git-cao-zuo/" title="git操作">git操作</a><time datetime="2022-02-23T07:47:18.000Z" title="发表于 2022-02-23 15:47:18">2022-02-23</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/12/20/springboot-xue-xi-bi-ji/" title="SpringBoot学习笔记">SpringBoot学习笔记</a><time datetime="2021-12-20T05:43:26.000Z" title="发表于 2021-12-20 13:43:26">2021-12-20</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/11/30/kmp-zhuan-ti/" title="KMP专题">KMP专题</a><time datetime="2021-11-30T14:58:55.000Z" title="发表于 2021-11-30 22:58:55">2021-11-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/10/linux-chang-yong-ming-ling/" title="linux常用命令">linux常用命令</a><time datetime="2021-09-10T05:10:03.000Z" title="发表于 2021-09-10 13:10:03">2021-09-10</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2021/09/10/mongodb-xue-xi-bi-ji/" title="MongoDB学习笔记">MongoDB学习笔记</a><time datetime="2021-09-10T04:23:12.000Z" title="发表于 2021-09-10 12:23:12">2021-09-10</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By TechAoba</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true,"scale":0.5},"react":{"opacity":0.7,"opacityOnHover":0.8}});</script></body></html>